\chapter{Processi e Metodi}
\label{cap:processi-metodologie}

\indent Questo capitolo fornisce in dettaglio l'ambiente di ricerca utilizzato, le tecnologie impiegate e descrive gli esperimenti condotti. 
Provvede a dare inoltre tutte le informazioni necessarie per replicare gli esperimenti.

\section{Ambiente}  
~\\  
\indent In questa sezione vengono descritti gli strumenti utilizzati durante il progetto, con le relative versioni riassunte nella Tabella \ref{table-tecnologie}.  
\\  
L'intero progetto è stato sviluppato su \textbf{\emph{MacOS}}\footnote{\url{https://support.apple.com/en-us/111893}}. La scelta di questo sistema operativo è stata motivata dalla familiarità con l'ecosistema Apple e dalle elevate prestazioni del processore, oltre che dalla vasta disponibilità di strumenti per l'analisi e lo sviluppo.  
\\  
Per la decompilazione degli eseguibili è stato utilizzato \textbf{\emph{Ghidra}}\footnote{\url{https://ghidra-sre.org/}}, uno strumento open source per l'ingegneria inversa, sviluppato dalla NSA's Research Directorate. La scelta è ricaduta su questo software poiché è open source e già noto al tirocinante.  
\\  
Il codice è stato condiviso e mantenuto tramite \textbf{GitHub}\footnote{\url{https://github.com/}}.  
\\  
Per la realizzazione degli esperimenti, il linguaggio di programmazione principale impiegato è stato \textbf{Python}\footnote{\url{https://python.org/}}. Python è stato scelto per la sua versatilità e l'ampia disponibilità di librerie, che hanno facilitato lo sviluppo rapido di prototipi e script.  
\\  
Per la classificazione delle sottofamiglie di malware è stato utilizzato \textbf{AVClass2}\footnote{\url{https://github.com/malicialab/avclass}}, un tool open source sviluppato da MaliciaLab, che consente di classificare i campioni di malware in base a famiglia e sottofamiglia partendo da report in formato JSON.  
\\  
I campioni di malware sono stati scaricati da tre fonti affidabili e riconosciute: \textbf{Malshare}\footnote{\url{https://malshare.com/pull.php}}, \textbf{Malware Bazaar}\footnote{\url{https://bazaar.abuse.ch/}} e \textbf{VirusShare}\footnote{\url{https://virusshare.com/}}.  
\\  
Per la generazione dei report relativi a ciascun malware è stato utilizzato \textbf{VirusTotal}\footnote{\url{https://www.virustotal.com/}}, un servizio online di scansione antivirus che analizza file e URL per rilevare malware e fornire dettagli sulle minacce.  
\\  
Infine, per determinare la presenza di un packer in un malware, è stato impiegato \textbf{Detect it Easy (DiE)}\footnote{\url{https://github.com/horsicq/Detect-It-Easy}}, uno strumento popolare tra analisti di malware, esperti di cybersecurity e reverse engineer. DiE supporta l'analisi sia basata su firme che euristica, ed è compatibile con una vasta gamma di piattaforme, come Windows, Linux e MacOS. Grazie alla sua architettura adattabile e basata su script, DiE si distingue come uno degli strumenti più versatili nel settore.

\hfill
\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Tipo} & \textbf{Nome} & \textbf{Versione} \\
        \hline
        Applicativo & \emph{Chromium} & 131.0.6778.70 \\
        \hline
        Applicativo & \emph{Ghidra} & 11.1.2 \\
        \hline
        Applicativo & \emph{Git} & 2.46.0 \\
        \hline
        Applicativo & \emph{Github} &  \\
        \hline
        Applicativo & \emph{AVClass2} & 2.0.0 \\
        \hline
        Applicativo & \emph{DiE} & 3.10.0 \\
        \hline
        Applicativo & \emph{Visual Studio Code} & 1.95.3 \\
        \hline
        Sistema Operativo & \emph{MacOS} & Sonoma 14.6.0 \\
        \hline
        Linguaggio & \emph{Python} & 3.13.0 \\
        \hline
    \end{tabular}
    \vspace*{.2cm}
    \caption{\emph{Tabella riassuntiva tecnologie usate}}
    \label{table-tecnologie}
\end{table}

\subsection{Svolgimento del Progetto}
Il progetto è stato sviluppato attraverso una serie di fasi distinte, ognuna delle quali ha contribuito in modo significativo alla creazione di un sistema per l'analisi e la generazione di malware. Le fasi del progetto sono descritte di seguito:

\begin{enumerate}
    \item \textbf{Preparazione dell'ambiente di sviluppo}: 
    In questa fase iniziale è stato configurato l'ambiente di sviluppo, includendo l'installazione di un ambiente virtuale, delle librerie necessarie e il setup della repository GitHub. Quest'ultima è stata organizzata in modo strutturato, con cartelle dedicate sia allo sviluppo pratico del progetto sia alla documentazione teorica (la tesi). Inoltre, è stata creata una struttura di base per il progetto, con directory principali e file di configurazione essenziali, per garantire un workflow ordinato ed efficiente.

    \item \textbf{Ricerca, raccolta e classificazione dei dati}: 
    Sono stati individuati dataset contenenti campioni di malware da fonti affidabili e riconosciute, come \textbf{VirusShare}, \textbf{MalwareBazaar} e \textbf{Malshare}. Ogni campione raccolto è stato analizzato tramite \textbf{VirusTotal}, che ha fornito report dettagliati. Successivamente, è stato utilizzato lo strumento \textbf{AVClass2} per classificare i malware nelle rispettive famiglie, basandosi sulle loro caratteristiche principali. Questo processo ha garantito un dataset ben strutturato e pronto per le fasi successive.

    \item \textbf{Preprocessing}: 
    I campioni di malware sono stati disassemblati per estrarre il loro codice in formato esadecimale e assembly. In particolare, dall'assembly sono state selezionate esclusivamente le istruzioni mnemoniche, ignorando altri tipi di dati. Successivamente, sono state generate coppie di mnemonici consecutivi per catturare le relazioni tra le operazioni eseguite dal malware. 

    Per analizzare queste coppie, è stata applicata la tecnica \textbf{TF-IDF} (Term Frequency - Inverse Document Frequency), che ha permesso di identificare le coppie più distintive e rilevanti riducendo l'influenza di quelle troppo comuni. Successivamente, è stata utilizzata la \textbf{PCA} (Principal Component Analysis) per ridurre la dimensionalità dei dati, identificando le caratteristiche chiave. Dai componenti principali è stata creata una matrice 16x16, che rappresenta una "impronta" comportamentale del malware. Questa matrice è stata normalizzata utilizzando la tecnica \textbf{Min-Max Scaling}, mappando i valori su un intervallo [0, 255] per consentire la conversione in immagini in scala di grigi. La formula utilizzata per la normalizzazione è:

    \[
    M'_{ij} = \frac{M_{ij} - \min(M)}{\max(M) - \min(M)} \times 255
    \]

    Dove:
    \begin{itemize}
        \item \( M_{ij} \) è il valore originale nella posizione \( (i, j) \) della matrice.
        \item \( \min(M) \) e \( \max(M) \) sono rispettivamente il valore minimo e massimo della matrice.
        \item \( M'_{ij} \) è il valore normalizzato, corrispondente all'intensità di un pixel.
    \end{itemize}

    Infine, le immagini generate sono state utilizzate come input per il modello di rete neurale convoluzionale.

    \item \textbf{Addestramento della CNN}: 
    È stata progettata e addestrata una rete neurale convoluzionale (\textbf{CNN}) per la classificazione dei malware. La CNN ha ricevuto in input le immagini generate durante il preprocessing. Il dataset è stato suddiviso in tre parti: 80\% per l'addestramento, 10\% per il test e 10\% per la validazione. La rete includeva:
    \begin{itemize}
        \item Due strati convoluzionali con 64 filtri ciascuno, seguiti da strati di max pooling.
        \item Un terzo strato convoluzionale con max pooling.
        \item Strati fully connected, con uno strato \textit{Flatten}, due strati \textit{Dense} e uno strato \textit{Dropout} per ridurre il rischio di overfitting.
    \end{itemize}
    L'addestramento è stato eseguito con tecniche di regolarizzazione e ottimizzazione degli iperparametri per migliorare le prestazioni. La CNN è stata valutata in termini di accuratezza e precisione sulla classificazione delle famiglie di malware. La struttura del modello è riportata in Figura \ref{fig:cnn_architecture}.

    \item \textbf{Creazione e utilizzo della GAN}: 
    Una \textbf{Generative Adversarial Network (GAN)} è stata sviluppata per generare nuovi campioni di malware. La GAN è composta da due componenti:
    \begin{itemize}
        \item \textbf{Generatore}, il quale crea immagini di malware sintetiche partendo da un vettore di rumore casuale.
        \item \textbf{Discriminatore}, che valuta la qualità delle immagini generate confrontandole con campioni reali.
    \end{itemize}
    Le immagini generate sono state utilizzate per mettere alla prova il modello di classificazione pre-addestrato. Attraverso un processo iterativo, è stato introdotto rumore crescente per verificare se il modello potesse essere ingannato. Ogni immagine è stata sottoposta a un massimo di dieci iterazioni, registrando metriche come accuratezza e numero di iterazioni necessarie per alterare la predizione del modello.

    Grafici dettagliati sono stati generati per ogni categoria di malware, includendo:
    \begin{itemize}
        \item \textbf{Grafici a barre}: Mostrano l'accuratezza media con intervalli di confidenza.
        \item \textbf{Grafici smussati}: Evidenziano l'andamento generale delle prestazioni del modello.
        \item \textbf{Heatmap}: Rappresentano visivamente le performance per ciascun campione.
    \end{itemize}

    \item \textbf{Esperimenti e analisi dei risultati}: 
    Sono stati condotti esperimenti per valutare sia la CNN che la GAN. La CNN è stata valutata in termini di accuratezza e precisione nella classificazione dei malware, mentre la GAN è stata analizzata in base alla qualità e somiglianza dei campioni generati rispetto a quelli reali. I risultati sono stati analizzati per identificare punti di forza e aree di miglioramento.

    \item \textbf{Conclusioni e sviluppi futuri}: 
    Il progetto ha dimostrato come le tecniche di deep learning, incluse CNN e GAN, possano essere utilizzate efficacemente per l'analisi e la generazione di malware. Sono state inoltre discusse potenziali direzioni future, come l'integrazione con analisi dinamiche o l'uso di tecniche multimodali per migliorare ulteriormente le prestazioni.
\end{enumerate}


\subsection{Tecnologie Specifiche per GAN}
~\\
\indent Per la realizzazione della componente blackbox all'interno della GAN, è stata utilizzata la libreria Keras di TensorFlow, uno strumento potente e flessibile per la costruzione di modelli di deep learning, disponibile per Python. Keras facilita l'implementazione di reti neurali complesse attraverso un'interfaccia di alto livello e modulare.
Il modello di rete neurale convoluzionale è stato sviluppato completamente da zero, addestrando un dataset appositamente creato e classificato dal tirocinante. Per la costruzione della GAN, invece, si è fatto riferimento all' architettura di un modello avanzato e già validato, MalGAN.

\footnote{\url{https://keras.io/}}
\footnote{\url{https://www.tensorflow.org/}}
\footnote{\url{https://github.com/lzylucy/Malware-GAN-attack}}


\section{Esperimenti}
~\\
\indent La sezione corrente esamina in dettaglio gli esperimenti condotti nel corso dello studio, illustrando la logica sottostante e le procedure impiegate per la loro realizzazione. 
L'obiettivo è fornire una panoramica completa delle attività sperimentali, cosicchè ci sia una maggiore comprensione sia dei metodi utilizzati che degli scopi.
\\\\
Gli esperimenti sono stati creati con l'obiettivo di identificare e testare diversi metodi per aumentare la precisione nel riconoscimento dei malware.
\\\\
I relativi risultati vengono analizzati nel Capitolo \ref{cap:risultati} mentre le conclusioni raggiunte sono discusse nel Capitolo \ref{cap:conclusioni}.
\\\\
Gli esperimenti sono stati condotti sotto le stesse condizioni per assicurare la veridicibilità dei risultati, ovvero \textbf{dataset suddiviso nello stesso modo}, \textbf{random state} e \textbf{numero di epoche uguali}. 


\subsection{Addestramento della CNN}
\subsubsection{Esperimento 1}
\begin{lstlisting}[caption={Primo modello di CNN creato},captionpos=b]
model = Sequential([
    Conv2D(128, (3, 3), input_shape=(SIZE, SIZE, 1),
            padding='same', activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), #input_shape=(SIZE//2, SIZE//2, 1),
            padding='same', activation='relu'),
    MaxPooling2D(2, 2),

    Conv2D(32, (3, 3), #input_shape=(SIZE//4, SIZE//4, 1),
            padding='same',  activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(len(categories), activation='softmax')
])
\end{lstlisting}
\subsubsubsection{Descrizione}
La struttura del modello è organizzata come segue:
\begin{itemize}
    \item \textbf{Strati convoluzionali:} La rete include tre strati convoluzionali. 
    Il primo strato applica 128 filtri di dimensione $3 \times 3$ sull'immagine di input, preservandone la dimensione originale grazie all'opzione di \textit{padding} \texttt{same}. 
    Gli strati successivi applicano rispettivamente 64 e 32 filtri, sempre di dimensione $3 \times 3$, continuando a preservare le dimensioni dei dati. 
    Tutti gli strati convoluzionali utilizzano la funzione di attivazione \texttt{ReLU}, che introduce non linearità e migliora la capacità del modello di apprendere rappresentazioni complesse.

    \item \textbf{Strati di pooling:} Dopo ogni strato convoluzionale, è presente uno strato di \textit{MaxPooling} con una finestra $2 \times 2$. 
    Questo riduce le dimensioni spaziali dell'input, abbassando la complessità computazionale e il rischio di overfitting, preservando al contempo le caratteristiche più significative.

    \item \textbf{Strato \textit{Flatten}:} Dopo gli strati convoluzionali e di pooling, il \textit{Flatten} converte i dati bidimensionali in un vettore unidimensionale, rendendoli compatibili con gli strati \textit{fully connected}.

    \item \textbf{Strati fully connected:} La rete include due strati completamente connessi (\textit{Dense}). 
    Il primo strato ha 64 unità ed è seguito da uno strato di \textit{Dropout} con un tasso di 0.5 per ridurre il rischio di overfitting. 
    Il secondo strato \textit{Dense}, con un numero di unità pari al numero di categorie di classificazione, utilizza la funzione di attivazione \texttt{softmax} per produrre le probabilità di appartenenza di ciascuna immagine a una specifica categoria.
\end{itemize}
L'architettura complessiva è ottimizzata per gestire immagini in scala di grigi con dimensioni $SIZE \times SIZE$ (nel nostro caso, $16 \times 16$) come input. La sequenza di strati convoluzionali consente di estrarre caratteristiche locali a diversi livelli di astrazione, mentre gli strati \textit{fully connected} sintetizzano queste caratteristiche per effettuare una classificazione accurata. 
L'uso di tecniche di regolarizzazione, come il \textit{Dropout}, migliora la capacità del modello di generalizzare ai dati di test, riducendo l'overfitting.


\subsubsection{Esperimento 2}
\begin{lstlisting}[caption={Secondo modello di CNN creato},captionpos=b]
model = Sequential([
    Conv2D(128, (3, 3), input_shape=(SIZE, SIZE, 1),
           padding='same', activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), input_shape=(SIZE//2, SIZE//2, 1),
           padding='same', activation='relu'),
    MaxPooling2D(2, 2),

    Conv2D(32, (3, 3), input_shape=(SIZE//4, SIZE//4, 1),
           padding='same',  activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.9),
    Dense(len(categories), activation='softmax')
])
\end{lstlisting}
\subsubsubsection{Descrizione}
La configurazione del modello è descritta come segue:
\begin{itemize}
    \item \textbf{Strati convoluzionali:} 
    Il modello utilizza tre strati convoluzionali per estrarre caratteristiche locali a diversi livelli di astrazione. 
    \begin{itemize}
        \item Il primo strato convoluzionale applica 128 filtri di dimensione $3 \times 3$ all'immagine di input con dimensioni $(SIZE, SIZE, 1)$. Grazie all'opzione di \textit{padding} \texttt{same}, la dimensione spaziale dell'immagine viene preservata. 
        \item Il secondo strato convoluzionale applica 64 filtri di dimensione $3 \times 3$, anch'essi con \textit{padding} \texttt{same}, su un'immagine di dimensioni ridotte $(SIZE/2, SIZE/2, 1)$.
        \item Il terzo strato convoluzionale utilizza 32 filtri di dimensione $3 \times 3$, sempre con \textit{padding} \texttt{same}, su un input ulteriormente ridotto $(SIZE/4, SIZE/4, 1)$.
    \end{itemize}
    Tutti gli strati convoluzionali utilizzano la funzione di attivazione \texttt{ReLU} per introdurre non linearità e facilitare l'apprendimento di rappresentazioni complesse.

    \item \textbf{Strati di pooling:} 
    Dopo ciascuno strato convoluzionale, il modello include uno strato di \textit{MaxPooling} con una finestra $2 \times 2$. Questa operazione riduce progressivamente la dimensione spaziale dell'input, concentrando l'attenzione sulle caratteristiche più significative e abbassando la complessità computazionale.

    \item \textbf{Strato \textit{Flatten}:} 
    Dopo gli strati convoluzionali e di pooling, i dati vengono appiattiti in un vettore unidimensionale tramite uno strato \textit{Flatten}, rendendoli adatti per l'elaborazione negli strati completamente connessi.

    \item \textbf{Strati fully connected:} 
    Il modello include due strati completamente connessi (\textit{Dense}):
    \begin{itemize}
        \item Il primo strato \textit{Dense} contiene 64 unità con attivazione \texttt{ReLU}. 
        \item Un \textit{Dropout} con tasso pari a 0.9 è applicato dopo il primo strato fully connected, per ridurre il rischio di overfitting, rendendo il modello più robusto.
        \item Il secondo strato \textit{Dense} utilizza un numero di unità pari al numero di categorie (\texttt{len(categories)}) e impiega la funzione di attivazione \texttt{softmax} per calcolare la probabilità di appartenenza a ciascuna classe.
    \end{itemize}
\end{itemize}
L'architettura è progettata per gestire immagini in scala di grigi di dimensione $SIZE \times SIZE$, estrarre caratteristiche locali tramite strati convoluzionali e di pooling, e sintetizzare tali informazioni nei livelli completamente connessi per ottenere una classificazione accurata. L'elevato tasso di \textit{Dropout} garantisce una maggiore generalizzazione del modello, riducendo la sensibilità al rumore nei dati di training.


\subsubsection{Esperimento 3}
\begin{lstlisting}[caption={Terzo modello di CNN creato},captionpos=b]
class MalwareModelHyperModel(HyperModel):
    def __init__(self, num_classes):
        self.num_classes = num_classes

    def build(self, hp):
        model = Sequential([
            Conv2D(hp.Int('conv_1_filters', 32, 128, step=32), (3, 3), input_shape=(SIZE, SIZE, 1), padding='same', activation='relu'),
            MaxPooling2D(2, 2),
            Conv2D(hp.Int('conv_2_filters', 32, 64, step=32), (3, 3), padding='same', activation='relu'),
            MaxPooling2D(2, 2),
            Conv2D(hp.Int('conv_3_filters', 32, 64, step=32), (3, 3), padding='same', activation='relu'),
            MaxPooling2D(2, 2),
            Flatten(),
            Dense(hp.Int('dense_units', 32, 128, step=32), activation='relu'),
            Dropout(hp.Float('dropout', 0.0, 0.5, step=0.1)),
            Dense(self.num_classes, activation='softmax')
        ])
        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
        return model

hypermodel = MalwareModelHyperModel(num_classes)

tuner = RandomSearch(
    hypermodel,
    objective='val_accuracy',
    max_trials=10,
    executions_per_trial=5,
    directory='my_dir',
    project_name='malware_classification_tuning'
)

tuner.search(X_train, y_train, epochs=30, validation_data=(X_val, y_val))
best_model = tuner.get_best_models(num_models=1)[0]
best_model.save(f'{value}/models/malware_classification_model_best.h5')

model = best_model
\end{lstlisting}
\subsubsubsection{Descrizione}
La struttura del modello e il processo di tuning sono descritti come segue:
\begin{itemize}
    \item \textbf{Struttura del modello:} 
    La rete CNN è composta da una sequenza di strati convoluzionali, di pooling e completamente connessi:
    \begin{itemize}
        \item \textbf{Strati convoluzionali:} La rete include tre strati convoluzionali, ciascuno con parametri configurabili:
        \begin{itemize}
            \item Il numero di filtri per ciascun livello (\texttt{conv\_1\_filters}, \texttt{conv\_2\_filters}, \texttt{conv\_3\_filters}) viene selezionato dinamicamente tra 32 e 128 per il primo strato e tra 32 e 64 per gli altri, con incrementi di 32. 
            \item Tutti gli strati convoluzionali utilizzano una finestra \(3 \times 3\), \textit{padding} \texttt{same} e la funzione di attivazione \texttt{ReLU}.
        \end{itemize}
        \item \textbf{Strati di pooling:} Dopo ciascun livello convoluzionale, uno strato di \textit{MaxPooling} con una finestra \(2 \times 2\) riduce progressivamente le dimensioni spaziali dell'input, mantenendo le caratteristiche più significative.
        \item \textbf{Strato \textit{Flatten}:} I dati bidimensionali risultanti dagli strati convoluzionali e di pooling vengono convertiti in un vettore unidimensionale tramite uno strato \textit{Flatten}.
        \item \textbf{Strati completamente connessi:} 
        \begin{itemize}
            \item Un primo strato completamente connesso (\textit{Dense}) ha un numero di unità configurabile (\texttt{dense\_units}) tra 32 e 128, selezionato in incrementi di 32, con funzione di attivazione \texttt{ReLU}.
            \item Un livello di \textit{Dropout}, con un tasso configurabile (\texttt{dropout}) tra 0.0 e 0.5 in incrementi di 0.1, aiuta a ridurre il rischio di overfitting.
            \item Lo strato finale \textit{Dense} ha un numero di unità pari al numero di classi (\texttt{self.num\_classes}) e utilizza la funzione di attivazione \texttt{softmax} per produrre la probabilità di appartenenza a ciascuna classe.
        \end{itemize}
    \end{itemize}

    \item \textbf{Compilazione del modello:} 
    Il modello viene compilato utilizzando l'ottimizzatore \texttt{adam}, la funzione di perdita \texttt{categorical\_crossentropy} e la metrica \texttt{accuracy}.

    \item \textbf{Tuning degli iperparametri:} 
    Per ottimizzare le prestazioni del modello, è stato utilizzato il \textit{Random Search} tramite la libreria \texttt{Keras Tuner}. Il processo di ricerca ha incluso i seguenti dettagli:
    \begin{itemize}
        \item \textbf{Oggetto \texttt{tuner}:} Il tuner esplora una combinazione di iperparametri basandosi su 10 prove (\texttt{max\_trials}), con 5 esecuzioni per ciascuna prova (\texttt{executions\_per\_trial}).
        \item \textbf{Obiettivo:} Il tuning è stato ottimizzato rispetto alla metrica \texttt{val\_accuracy}.
        \item \textbf{Set di dati:} La ricerca degli iperparametri è stata condotta utilizzando il set di addestramento (\texttt{X\_train}, \texttt{y\_train}) e di validazione (\texttt{X\_val}, \texttt{y\_val}) per 30 epoche.
        \item \textbf{Miglior modello:} Una volta completata la ricerca, il miglior modello è stato selezionato (\texttt{get\_best\_models}) e salvato per l'utilizzo futuro.
    \end{itemize}

    \item \textbf{Salvataggio del modello:} 
    Il modello con i parametri ottimali è stato salvato nel percorso \texttt{malware\_classification\_model\_best.h5} per consentire un utilizzo successivo.
\end{itemize}


\subsection{Addestramento della GAN}

\subsubsection{Esperimento 1}
% \begin{lstlisting}[caption={Primo modello di GAN generato},captionpos=b]
% def build_generator(latent_dim):
%     noise = Input(shape=(latent_dim,))
%     x = Dense(256, activation="relu")(noise)
%     img = Reshape((16, 16, 1))(x)
%     return Model(inputs=noise, outputs=img, name="generator")

% def build_discriminator(input_shape):
%     input_img = Input(shape=input_shape)
%     x = Flatten()(input_img)
%     x = Dense(128, activation="relu")(x)
%     x = Dense(64, activation="relu")(x)
%     output = Dense(1, activation="sigmoid")(x)
%     return Model(inputs=input_img, outputs=output, name="discriminator")
% \end{lstlisting}

% \subsubsubsection{Descrizione}
% Di seguito sono riportate le caratteristiche strutturali di ciascun componente:
% \begin{itemize}
%     \item \textbf{Generatore:} 
%     Il generatore è progettato per creare immagini sintetiche a partire da un vettore di rumore casuale. La sua architettura è descritta come segue:
%     \begin{itemize}
%         \item L'input è rappresentato da un vettore di rumore di dimensione pari a \texttt{latent\_dim}.
%         \item Il vettore passa attraverso uno strato \textit{Dense} con 256 unità e funzione di attivazione \texttt{ReLU}, che trasforma il rumore in una rappresentazione ad alta dimensione.
%         \item L'output dello strato \textit{Dense} viene ridimensionato in una matrice \(16 \times 16 \times 1\) utilizzando lo strato \textit{Reshape}, che converte il vettore unidimensionale in un formato bidimensionale con un singolo canale (scala di grigi).
%         \item Il modello finale ha come input il vettore di rumore e come output un'immagine sintetica di dimensione \(16 \times 16\).
%     \end{itemize}

%     \item \textbf{Discriminatore:} 
%     Il discriminatore è progettato per distinguere tra immagini sintetiche (generate) e immagini reali. La sua architettura è descritta come segue:
%     \begin{itemize}
%         \item L'input del modello è un'immagine di dimensione \(16 \times 16 \times 1\).
%         \item L'immagine viene convertita in un vettore unidimensionale utilizzando uno strato \textit{Flatten}.
%         \item Il vettore passa attraverso due strati \textit{Dense} con 128 e 64 unità, entrambi con funzione di attivazione \texttt{ReLU}, che estraggono caratteristiche significative dalle immagini.
%         \item Lo strato finale \textit{Dense} ha una singola unità con funzione di attivazione \texttt{sigmoid}, che produce un output scalare compreso tra 0 e 1. Questo valore rappresenta la probabilità che l'immagine di input sia reale (vicina a 1) o generata (vicina a 0).
%     \end{itemize}
% \end{itemize}
% Questa architettura rappresenta la base di una Generative Adversarial Network, in cui il generatore e il discriminatore competono tra loro in un processo iterativo per migliorare reciprocamente le loro prestazioni.

% \subsubsection{Esperimento 2} 