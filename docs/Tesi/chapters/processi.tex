\chapter{Processi e Metodi}
\label{cap:processi-metodologie}

\indent Questo capitolo fornisce in dettaglio l'ambiente di ricerca utilizzato, le tecnologie impiegate e descrive gli esperimenti condotti. 
Provvede a dare inoltre tutte le informazioni necessarie per replicare gli esperimenti.

\section{Ambiente}
~\\
\indent Questa sezione offre una panoramica completa dell'ambiente di lavoro e delle tecnologie impiegate nello sviluppo degli esperimenti descritti successivamente. 
Di seguito, viene riportata una descrizione degli strumenti utilizzati durante lo svolgimento del progetto (riassunte con le relative versioni nella Tabella \ref{table-tecnologie}).
\\\\
La totalità del progetto è stata svolta su \textbf{\emph{MacOS}}\footnote{\url{https://support.apple.com/en-us/111893}}. 
Questa scelta di sistema operativo è dovuta al vasto supporto di strumenti per l'analisi e lo sviluppo.
\\\\
Per la decompilazione degli eseguibili è stato utilizzato \textbf{\emph{Ghidra}}\footnote{\url{https://ghidra-sre.org/}}, 
uno strumento per effettuare ingegneria inversa sviluppato da NSA's Research Directorate e rilasciato come software libero.
\\\\
Per la condivisione e mantenimento del codice si è usato \textbf{GitHub}\footnote{\url{https://github.com/}}.
\\\\
Per la realizzazione degli esperimenti si è utilizzato \textbf{Python}\footnote{\url{https://ghidra-sre.org/}} come linguaggio di programmazione principale, in quanto versatile e permette di sviluppare rapidamente prototipi e script e ha a disposizione molte librerie in supporto allo scopo di questo progetto.
\\\\
Per la classificazione delle sottofamiglie è stato impiegato \textbf{AVClass2}\footnote{\url{https://github.com/malicialab/avclass}}
un tool open source sviluppato da MaliciaLab che permette di classificare i campioni di malware in base alla famiglia e alla sottofamiglia partendo da un report in formato json.
\\\\
Per il download dei campioni di malware sono stati impiegati tre siti affidabili e riconosciuti, tra cui \textbf{Malshare}\footnote{\url{https://malshare.com/pull.php}}, \textbf{Malware Bazaar}\footnote{\url{https://bazaar.abuse.ch/}} e \textbf{VirusShare}\footnote{\url{https://virusshare.com/}}.
\\\\
Per la generazione dei report per ciascun malware è stato impiegato \textbf{VirusTotal}\footnote{\url{https://www.virustotal.com/}}, un servizio di scansione antivirus online che analizza i file e le URL per rilevare malware e fornire dettagli sulle minacce.
\\\\
Per capire se un malware ha o meno un packer è stato usato \textbf{Detect it Easy (DiE)}\footnote{\url{https://www.google.com}}

%TODO: sistemare DIE e spiegare cos'è e per cosa è stato usato



\subsection{Tecnologie Specifiche per GAN}
~\\
\indent Per la creazione della blackbox utilizzata all'interno della GAN è stata usata la libreria Keras di TensorFlow, disponibile per python. Il modello CNN è stato addestrato completamente da zero, con un dataset interamente creato e classificato dal tirocinante mediante gli strumenti precedentemente citati. Per la creazioen della GAN invece si è fatto riferimento all'architettura di tecnologie già esistenti, come MalGAN, Xception, Inception ecc.. in quanto già testate e super accurate. (aggiungere magari discorso dell'accuratezza al 99\% ecc...)


\subsection{Tecnologie Specifiche per Dataset}
~\\
%TODO aggiungere cosa si è fatto
\hfill
\begin{table}[!h]
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textbf{Tipo} & \textbf{Nome} & \textbf{Versione} \\
        \hline
        Applicativo & \emph{Arc} & Versione attuale \\
        \hline
        Applicativo & \emph{Ghidra} & Versione attuale \\
        \hline
        Applicativo & \emph{Github} & Versione attuale \\
        \hline
        Applicativo & \emph{AVClass2} & Versione attuale \\
        \hline
        Applicativo & \emph{DiE} & Versione attuale \\
        \hline
        Applicativo & \emph{Visual Studio Code} & Versione attuale \\
        \hline
        Sistema Operativo & \emph{MacOS} & Versione attuale \\
        \hline
        Linguaggio & \emph{Python} & Versione attuale \\
        \hline
    \end{tabular}
    \caption{\emph{Tabella riassuntiva tecnologie usate}}
    \label{table-tecnologie}
\end{table}

\section{Esperimenti}
~\\
\indent La sezione corrente esamina in dettaglio gli esperimenti condotti nel corso dello studio, illustrando la logica sottostante e le procedure impiegate per la loro realizzazione. 
L'obiettivo è fornire una panoramica completa delle attività sperimentali, cosicchè ci sia una maggiore comprensione sia dei metodi utilizzati che degli scopi.
\\\\
Gli esperimenti sono stati creati con l'obiettivo di identificare e testare diversi metodi per aumentare la precisione nel riconoscimento dei malware.
\\\\
I relativi risultati vengono analizzati nel Capitolo \ref{cap:risultati} mentre le conclusioni raggiunte sono discusse nel Capitolo \ref{cap:conclusioni}.

\subsection{Esperimenti relativi a qualche tipo di GAN applicata}
~\\ 
%TODO aggiungere dettagli come per esempio la percentuale di riconoscimento delle famiglie di malware. 




% % QUESTA PARTE VA MESSA PER SPIEGARE DOPO LE COPPIE MNEMONICHE:
% In particolare, dall'assembly si è scelto di considerare solo le istruzioni mnemoniche, ignorando qualsiasi altro tipo di dato. Questi mnemonici rappresentano le operazioni fondamentali svolte dal codice, fornendo una sintesi compatta e significativa del comportamento del malware. Dopo aver estratto i mnemonici, si sono generate tutte le possibili coppie di mnemonici, cioè sequenze di due istruzioni consecutive, per catturare le relazioni immediate tra le operazioni eseguite.

% Una volta ottenute le coppie di mnemonici, si è applicata la tecnica TF-IDF (Term Frequency - Inverse Document Frequency), che consente di quantificare l'importanza di ciascuna coppia nel contesto dell'intero dataset. L'uso di TF-IDF permette di ridurre l'influenza di coppie di mnemonici troppo comuni (meno informative) e di enfatizzare quelle che risultano particolarmente distintive per certe famiglie di malware.

% Dopo l'applicazione di TF-IDF, si è proceduto con una riduzione dimensionale utilizzando la PCA (Principal Component Analysis), selezionando i componenti principali che meglio rappresentano la variabilità nei dati. Questo ha consentito di ridurre la complessità delle informazioni mantenendo al contempo una buona rappresentazione delle caratteristiche distintive del malware.

% Dai componenti principali ottenuti, si è generata una matrice di dimensione 16x16, che rappresenta una sorta di "impronta" del comportamento del malware. Questa matrice è stata poi normalizzata utilizzando la tecnica Min-Max Scaling, che trasforma i valori della matrice in un range tra 0 e 255, permettendo così di rappresentarli come intensità di pixel.

% Infine, la matrice normalizzata è stata convertita in un'immagine in scala di grigi, dove ogni pixel rappresenta un valore numerico della matrice scalato tra 0 (nero) e 255 (bianco). Questo processo ha portato alla generazione di immagini di dimensione 16x16 pixel, che sono utilizzate come input per la rete neurale convoluzionale.
